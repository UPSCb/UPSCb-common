---
title: "Differential Expression"
author: "Insert author name"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_width: 12
    fig_height: 9
    toc: true
    number_sections: true
    toc_depth: 3
    toc_float:
      collapsed: TRUE
      smooth_scroll: TRUE
    code_folding: hide
    theme: "flatly"
    highlight: pygments
  includes:
    before_body: header.html
    after_body: footer.html
  css: style.css
---

````{r opts, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
````

<details><summary>Setup</summary>

* Libraries

````{r }
suppressPackageStartupMessages({
    library(data.table)
    library(DESeq2)
    library(emoji)
    library(gplots)
    library(here)
    library(hyperSpec)
    library(RColorBrewer)
    library(tidyverse)
    library(VennDiagram)
})
````

* Helper files

````{r }
suppressMessages({
    source(here("UPSCb-common/Rtoolbox/src/plotEnrichedTreemap.R"))
    source(here("UPSCb-common/src/R/featureSelection.R"))
    source(here("UPSCb-common/src/R/volcanoPlot.R"))
})
````

* Graphics

````{r }
pal=brewer.pal(8,"Dark2")
hpal <- colorRampPalette(c("blue","white","red"))(100)
mar <- par("mar")
````

* Functions

  * Plot specific gene expression

````{r line_plot}
"line_plot" <- function(dds=dds,vst=vst,gene_id=gene_id){
    message(paste("Plotting",gene_id))
    sel <- grepl(gene_id,rownames(vst))
    stopifnot(sum(sel)==1)

    p <- ggplot(bind_cols(as.data.frame(colData(dds)),
                          data.frame(value=vst[sel,])),
                aes(x=Treatment,y=value,col=Treatment,group=Treatment)) +
        geom_point() + geom_smooth() +
        scale_y_continuous(name="VST expression") + 
        ggtitle(label=paste("Expression for: ",gene_id))
    
    suppressMessages(suppressWarnings(plot(p)))
    return(NULL)
}
````

  * Get suspicious genes
  
````{r get_suspicious_genes}
"get_suspicious_genes" <- function(vst,relevant_samples, threshold=10){

  vstdf <- as_tibble(vst[,unlist(relevant_samples)], rownames = "Gene")


  # Convert to long format for easier manipulation
  vstdf_long <- vstdf %>%
    pivot_longer(cols = -Gene, names_to = "sample", values_to = "expression")


  # Find the maximum length of the vectors in relevant_samples
  max_length <- max(sapply(relevant_samples, length))

  # Pad the vectors with NA to make them the same length
  padded_samples <- lapply(relevant_samples, function(x) {
    length(x) <- max_length
    x
  })

  # Convert to tibble
  group_info <- as_tibble(padded_samples) %>%
    pivot_longer(names_to = "group", values_to = "sample", cols = everything()) %>%
    arrange(group)

  # Add group information to vstdf_long
  vstdf_long <- vstdf_long %>%
    left_join(group_info, by = "sample")


  # First, I replace zeroes with values equal to half the minimum detected values.
  # This high values of z-replacement is so genes with very low expression values and 1 or 2 zeroes do not come up as suspicious
  # Calculate the minimum non-zero value in the expression column
  min_non_zero <- min(vstdf_long$expression[vstdf_long$expression > 0])

  # Define the low value as a small fraction of the minimum non-zero value
  low_value <- min_non_zero * 0.5  # Adjust the fraction as needed



  # Function to calculate the required values
  results <- vstdf_long %>%
    mutate(expression = ifelse(expression == 0, low_value, expression)) %>%
    group_by(Gene, group) %>%
    summarise(
      max_expr = max(expression),
      min_expr = min(expression),
      avg_expr = mean(expression),
      max_div_avg = max(expression) / mean(expression[expression != max(expression)]),
      avg_non_min = mean(expression[expression != min(expression)]),
      min_div_avg = avg_non_min / min(expression)
    ) %>%
    ungroup() %>%
    #As genes with only 0 values were returning NA in the max_div_avg and min_div_avg columns, I replace this values with 1
    mutate_all(~replace_na(., 1))


  # In the end I only use max_div_avg to determine suspicious genes
  suspicious_genes  <- results %>%
    filter(max_div_avg > threshold) %>%
    select(Gene) %>%
    distinct() %>%
    pull()


  return(suspicious_genes)
}
```` 

  * Load function to find out the name of columns not identical in two dataframes
  
````{r compare_columns}

compare_columns <- function(tibble1, tibble2) {
  # Initialize an empty vector to store names of non-identical columns
  non_identical_columns <- c()
  
  # Loop through each column in tibble1
  for (col in colnames(tibble1)) {
    # Check if the column exists in tibble2
    if (col %in% colnames(tibble2)) {
      # Compare the columns
      if (!all(tibble1[[col]] == tibble2[[col]])) {
        # If not identical, add the column name to the vector
        non_identical_columns <- c(non_identical_columns, col)
      }
    } else {
      # If the column does not exist in tibble2, add the column name to the vector
      non_identical_columns <- c(non_identical_columns, col)
    }
  }
  
  return(non_identical_columns)
}

````

  * Process a comparison of interest

````{r process_comparison}

process_comparison <- function(comparison, Interest_col, variables_interest, ...) {
  result_name <- gsub(" ", "", paste(comparison, collapse="vs"))
  
  result <- apply_extract_results(
    comparison = comparison,
    variables_interest = variables_interest,
    NameConditionColumn = Interest_col,
    default_prefix = paste0("DE-", result_name, "_"),
    ...
  )
  
  up <- tibble(Gene = result$up)
  down <- tibble(Gene = result$dn)
  
  write_tsv(up, here(paste0("data/analysis/DE/DE-", result_name, "_UP.tsv")), col_names = FALSE)
  write_tsv(down, here(paste0("data/analysis/DE/DE-", result_name, "_DOWN.tsv")), col_names = FALSE)
  
  return(result)
}

````

  * Plot information about changes in differential expression depending on the cooks cutoff:
  
```{r}

"plot_cooks_cutoffs" <- function(results_cooks_list, lfc, thres) {

## Plot 1
plotting_results <- lapply(results_cooks_list, function(x) {
  x[setdiff(names(x), "res")]
})

# Extract percentile values
names_list <- sapply(plotting_results, function(x) x$percentile)

# Set names of results_cooks_list
names(plotting_results) <- names_list

#Make a tibble for plotting
df <- t(as_tibble(plotting_results))

colnames(df) <- c("DEGs", "Suspicious_DEGs", "Percentile")

df <- df %>%
as_tibble() %>% 
  unnest(cols = c(DEGs, Suspicious_DEGs, Percentile))

original_DEGs <- plotting_results[["0.99"]]$DEGs


df <- df %>% mutate(Tens_lost_DEGs = (original_DEGs - DEGs)/10)

# Now we plot

p1 <- ggplot(df, aes(x = Percentile)) +
  geom_line(aes(y = Suspicious_DEGs, color = "Suspicious DEGs")) +
  geom_line(aes(y = Tens_lost_DEGs, color = "Tens of lost DEGs")) +
  scale_x_reverse() +
  labs(title = "Changes in suspicious DEGs and tens of lost DEGs by cooks percentile",
       x = "Percentile",
       y = "Gene number",
       color = "Legend") +
  theme_minimal()


  print(p1)


## Plot 2

names_list <- sapply(results_cooks_list, function(x) x$percentile)

expression_results <- lapply(results_cooks_list, function(x) {
  x[setdiff(names(x), c("suspicious", "DEGs", "percentile"))]
})

names(expression_results) <- names_list

expression_results <- unlist(expression_results)

expression_results <- map(expression_results, ~ as_tibble(.x, rownames = "Gene"))

original_DEGs <- expression_results[["0.99.res"]] %>%
    filter(log2FoldChange > lfc | log2FoldChange < -lfc) %>% 
    filter(!is.na(padj)) %>% 
    filter(padj < thres) %>% 
    select(Gene) %>% 
    pull()
    
    
# Define function to filter tibbles
process_tibble <- function(tibble, lfc, thres, original_DEGs) {
  tibble %>%
  filter(Gene %in% original_DEGs) %>% 
    filter(is.na(padj)) %>% 
    select(baseMean) %>%
    pull()
    }


# Apply the function to each tibble in the list
expression_results <- map2(expression_results, names(expression_results), ~setNames(list(process_tibble(.x, lfc, thres, original_DEGs)), .y))


# Convert to a single list of vectors
expression_results <- lapply(expression_results, function(x) setNames(unlist(x), NULL))


# Convert the list to a data frame
df <- melt(expression_results)
colnames(df) <- c("baseMean", "Percentile")

df$baseMean <- log10(df$baseMean)

chosen_percentiles <- df %>% select(Percentile) %>% distinct() %>% slice(seq(1, n(), by = 5)) %>% pull()

df <- df %>% filter(Percentile %in% chosen_percentiles)

# Visualize stuff

p2 <- ggplot(df, aes(x = Percentile, y = baseMean)) +
  geom_boxplot() +
  labs(title = "Box Plot of Vectors (Logarithmic Scale)",
       x = "Percentile",
       y = "Log(BaseMean) of removed DEGs")
       

print(p2)

}



```
  
  * Extract the DE results. Default cutoffs are from Schurch _et al._, RNA, 2016
  
  Suspicious degs are also returned now, users can autonomolusly decide if they want to keep them (they must be removed from the up and dn lists if that is the case)

````{r function_extract_results}
"extract_results" <- function(dds,vst,contrast, relevant_samples,
                              padj=0.01,lfc=0.5,
                              plot=TRUE,verbose=TRUE,
                              export=TRUE,default_dir=here("data/analysis/DE"),
                              default_prefix="DE-",
                              labels=colnames(dds),
                              sample_sel=1:ncol(dds),
                              cooks_percentile = 0.99,
                              cook_optimization = FALSE,
                              expression_cutoff=0,
                              debug=FALSE,filter=c("median",NULL),
                              double_step_filter=TRUE, ...){

  # get the filter
  # get the filter
  if(!is.null(match.arg(filter))){
    filter <- rowMedians(counts(dds,normalized=TRUE))
    filtering_strategy <- "median"
    message("Using the median normalized counts as default, set filter=NULL to revert to using the mean")
  }
  
  # Setting a cooks_cutoff according to the cooks_percentile parameter
  m <- ncol(counts(dds))
  
  p <- ncol(model.matrix(design(dds), colData(dds)))
  
  cooks_cutoff <- qf(cooks_percentile, p, m - p)
  
  
  # validation
  if(length(contrast)==1){
    res <- results(dds,name=contrast,filter = filter, cooksCutoff = cooks_cutoff)
  } else {
    res <- results(dds,contrast=contrast,filter = filter, cooksCutoff = cooks_cutoff)
  }
  
  stopifnot(length(sample_sel)==ncol(vst))
  
  if(double_step_filter==TRUE){
    # Remove samples not among the relevant_samples
    dds_relevant <- dds[, colnames(dds) %in% unlist(relevant_samples)]
    
    #Find factor columns
    factor_columns <- sapply(colData(dds_relevant), is.factor)
    factor_column_names <- names(colData(dds_relevant))[factor_columns]
    
    # Apply droplevels to each factor column
    for (element in factor_column_names) {
      dds_relevant[[element]] <- droplevels(dds_relevant[[element]])
    }
    
    #Repeat dds analysis
    
    dds_relevant <- DESeq(dds_relevant)
    
    # Set filter
    if(filtering_strategy == "median"){
      filter_relevant <- rowMedians(counts(dds_relevant,normalized=TRUE))
      message("Using the median normalized counts as default, set filter=NULL to revert to using the mean")
    }


    # Setting a cooks_cutoff for relevant samples according to the cooks_percentile parameter
    m_relevant <- ncol(counts(dds_relevant))

    p_relevant <- ncol(model.matrix(design(dds_relevant), colData(dds_relevant)))

    cooks_cutoff_relevant <- qf(cooks_percentile, p_relevant, m_relevant - p_relevant)


    # Extract the results considering only relevant samples
    if(length(contrast)==1){
      res_relevant <- results(dds_relevant,name=contrast,
                              filter = filter_relevant,
                              cooksCutoff = cooks_cutoff_relevant)
    } else {
      res_relevant <- results(dds_relevant,contrast=contrast,
                              filter = filter_relevant,
                              cooksCutoff = cooks_cutoff_relevant)
    }

    # Where a gene was removed by the cooks distance test, its pvalue and adjusted pvalue
    # will have been set to NA, while columns like log2FoldChange will have a value

    genes_to_remove <- as_tibble(res_relevant, rownames="Gene") %>%
      filter(is.na(padj) & is.na(pvalue)) %>%
      filter(!is.na(log2FoldChange)) %>%
      select(Gene) %>%
      pull()


    res$pvalue[rownames(res) %in% genes_to_remove] <- NA
    res$padj[rownames(res) %in% genes_to_remove] <- NA
  }

  #Find suspicious genes


  suspicious_genes <- get_suspicious_genes(vst, relevant_samples, threshold=10)

  thres <- padj

  suspicious_degs <- as_tibble(res, rownames = "Gene") %>%
    filter(Gene %in% suspicious_genes) %>%
    filter(log2FoldChange > lfc | log2FoldChange < -lfc) %>%
    filter(!is.na(padj)) %>%
    filter(padj < thres) %>%
    select(Gene) %>%
    pull()


  #Set maximum number of suspicious degs that I wnat to accept after the optimization phase, only if the suspicious degs are more than 10
  message(sprintf("The number of suspicious DEGs is %s",
                  length(suspicious_degs)))

  if (length(suspicious_degs) > 10) {
    maximum_suspicious <- length(suspicious_degs)/5


    # Checking for cooks optimization in any case, just to do the plots

    # Define a function to check the condition and update results
    optimize_cooks <- function(cooks_percentile) {
      cooks_cutoff <- qf(cooks_percentile, p, m - p)
      res <- if (length(contrast) == 1) {
        results(dds, name = contrast, filter = filter, cooksCutoff = cooks_cutoff)
      } else {
        results(dds, contrast = contrast, filter = filter, cooksCutoff = cooks_cutoff)
      }
    
      suspicious_DEGs <- as_tibble(res, rownames = "Gene") %>%
        filter(Gene %in% suspicious_genes) %>%
        filter(log2FoldChange > lfc | log2FoldChange < -lfc) %>%
        filter(!is.na(padj)) %>%
        filter(padj < thres) %>%
        select(Gene) %>%
        pull() %>%
        length()
    
      DEGs <- as_tibble(res, rownames="Gene") %>%
        filter(log2FoldChange > lfc | log2FoldChange < -lfc) %>%
        filter(!is.na(padj)) %>%
        filter(padj < thres) %>%
        select(Gene) %>%
        pull() %>%
        length()
    
      list(res = res, DEGs=DEGs, suspicious = suspicious_DEGs, percentile = cooks_percentile)
    }
    
    # Use map to iterate over cooks_percentile values
    results_cooks_list <- map(seq(0.99, 0.50, by = -0.01), optimize_cooks)

    # Extract the count of suspicious genes from results
    counts <- map_dbl(results_cooks_list, ~ .x$suspicious)



    if (cook_optimization == TRUE) {
      # Find the index where the condition is met
      index <- which(counts < maximum_suspicious)

      #Get the less stringent threshold that meets the condition, or the most stringent one if no threshold meets it

      if (length(index) > 0) {
        res <- results_cooks_list[[index[1]]]$res
        cooks_percentile <- results_cooks_list[[index[1]]]$percentile
      } else {
        res <- tail(results_cooks_list, 1)[[1]]$res
        cooks_percentile <- tail(results_cooks_list, 1)[[1]]$percentile
      }

      suspicious_degs <- as_tibble(res, rownames = "Gene") %>%
        filter(Gene %in% suspicious_genes) %>%
        filter(log2FoldChange > lfc | log2FoldChange < -lfc) %>%
        filter(!is.na(padj)) %>%
        filter(padj < thres) %>%
        select(Gene) %>%
        pull()

    }


    print(paste0("The cooks percentile was ", cooks_percentile, ", corresponding to a cooks cutoff of ", qf(cooks_percentile, p, m - p)))


    # Also do plots about the cooks cutoff optimization

    if(plot){
      plot_cooks_cutoffs(results_cooks_list=results_cooks_list, lfc=lfc, thres=padj)
    }

  }

  if(plot){
    par(mar=c(5,5,5,5))
    volcanoPlot(res)
    par(mar=mar)
  }

  # a look at independent filtering
  if(plot){
    plot(metadata(res)$filterNumRej,
         type="b", ylab="number of rejections",
         xlab="quantiles of filter")
    lines(metadata(res)$lo.fit, col="red")
    abline(v=metadata(res)$filterTheta)
  }

  if(verbose){
    message(sprintf("The independent filtering cutoff is %s, removing %s of the data",
                    round(metadata(res)$filterThreshold,digits=5),
                    names(metadata(res)$filterThreshold)))

    max.theta <- metadata(res)$filterNumRej[which.max(metadata(res)$filterNumRej$numRej),"theta"]
    message(sprintf("The independent filtering maximises for %s %% of the data, corresponding to a base mean expression of %s (library-size normalised read)",
                    round(max.theta*100,digits=5),
                    round(quantile(counts(dds,normalized=TRUE),probs=max.theta),digits=5)))
  }

  if(plot){
    qtl.exp=quantile(counts(dds,normalized=TRUE),probs=metadata(res)$filterNumRej$theta)
    dat <- data.frame(thetas=metadata(res)$filterNumRej$theta,
                      qtl.exp=qtl.exp,
                      number.degs=sapply(lapply(qtl.exp,function(qe){
                        res$padj <= padj & abs(res$log2FoldChange) >= lfc &
                          ! is.na(res$padj) & res$baseMean >= qe
                      }),sum))
    if(debug){
      plot(ggplot(dat,aes(x=thetas,y=qtl.exp)) +
             geom_line() + geom_point() +
             scale_x_continuous("quantiles of expression") +
             scale_y_continuous("base mean expression") +
             geom_hline(yintercept=expression_cutoff,
                        linetype="dotted",col="red"))

      p <- ggplot(dat,aes(x=thetas,y=qtl.exp)) +
        geom_line() + geom_point() +
        scale_x_continuous("quantiles of expression") +
        scale_y_log10("base mean expression") +
        geom_hline(yintercept=expression_cutoff,
                   linetype="dotted",col="red")
      suppressMessages(suppressWarnings(plot(p)))

      plot(ggplot(dat,aes(x=thetas,y=number.degs)) +
             geom_line() + geom_point() +
             geom_hline(yintercept=dat$number.degs[1],linetype="dashed") +
             scale_x_continuous("quantiles of expression") +
             scale_y_continuous("Number of DE genes"))

      plot(ggplot(dat,aes(x=thetas,y=number.degs[1] - number.degs),aes()) +
             geom_line() + geom_point() +
             scale_x_continuous("quantiles of expression") +
             scale_y_continuous("Cumulative number of DE genes"))

      plot(ggplot(data.frame(x=dat$thetas[-1],
                             y=diff(dat$number.degs[1] - dat$number.degs)),aes(x,y)) +
             geom_line() + geom_point() +
             scale_x_continuous("quantiles of expression") +
             scale_y_continuous("Number of DE genes per interval"))

      plot(ggplot(data.frame(x=dat$qtl.exp[-1],
                             y=diff(dat$number.degs[1] - dat$number.degs)),aes(x,y)) +
             geom_line() + geom_point() +
             scale_x_continuous("base mean of expression") +
             scale_y_continuous("Number of DE genes per interval"))

      p <- ggplot(data.frame(x=dat$qtl.exp[-1],
                             y=diff(dat$number.degs[1] - dat$number.degs)),aes(x,y)) +
        geom_line() + geom_point() +
        scale_x_log10("base mean of expression") +
        scale_y_continuous("Number of DE genes per interval") +
        geom_vline(xintercept=expression_cutoff,
                   linetype="dotted",col="red")
      suppressMessages(suppressWarnings(plot(p)))
    }
  }


  sel <- res$padj <= padj & abs(res$log2FoldChange) >= lfc & ! is.na(res$padj) &
    res$baseMean >= expression_cutoff

  if(verbose){
    message(sprintf(paste(
      ifelse(sum(sel)==1,
             "There is %s gene that is DE",
             "There are %s genes that are DE"),
      "with the following parameters: FDR <= %s, |log2FC| >= %s, base mean expression > %s"),
      sum(sel),padj,
      lfc,expression_cutoff))
  }

  # proceed only if there are DE genes
  if(sum(sel) > 0){
    val <- rowSums(vst[sel,sample_sel,drop=FALSE])==0
    if (sum(val) >0){
      warning(sprintf(paste(
        ifelse(sum(val)==1,
               "There is %s DE gene that has",
               "There are %s DE genes that have"),
        "no vst expression in the selected samples"),sum(val)))
      sel[sel][val] <- FALSE
    }

    if(export){
      if(!dir.exists(default_dir)){
        dir.create(default_dir,showWarnings=FALSE,recursive=TRUE,mode="0771")
      }
      write.csv(res,file=file.path(default_dir,paste0(default_prefix,"_results.csv")))
      write.csv(res[sel,],file.path(default_dir,paste0(default_prefix,"_genes.csv")))
    }
    par(mar=c(0,5,5,5)+0.1)
    if(plot & sum(sel)>1){
      heatmap.2(t(scale(t(vst[sel,sample_sel]))),
                distfun = pearson.dist,
                hclustfun = function(X){hclust(X,method="ward.D2")}, dendrogram='row',  Rowv=TRUE,
                trace="none",col=hpal,labRow = FALSE, srtCol = 45, margins=c(6,6),
                labCol=labels[sample_sel],...
      )
    }
  }
  return(list(all=rownames(res[sel,]),
              up=rownames(res[sel & res$log2FoldChange > 0,]),
              dn=rownames(res[sel & res$log2FoldChange < 0,]),
              suspicious=suspicious_degs))
}


````


* Apply extract results in a contrast-dependent manner

````{r apply_extract_results}

# variables_interest must be a vector containing all the names of column in samples containing variables across which the comparisons will run.

# For example, if you plan to run comparisons across Treatment and Time, then variables_interest shoulc be c("Treatment", "Time")

# NameConditionColumn must be the column from which you will pull the values to specify your comparison.
# For example, if the comparison is c("T0_treated", "T0_control"), then NameConditionColumn will need to specify which samples belong to each of these two groups.



"apply_extract_results" <- function(dds,
                                    samples,
                                    NameConditionColumn,
                                    comparison,
                                    variables_interest,
                                    ...)
{
  
  
  
  
  print(gsub(" ", "", paste(comparison, collapse="vs")))
  
  #Make a new column whose value is equal to NameConditionColumn
  
  samples$NewCol <- samples[[NameConditionColumn]]
  
  # Determine the correct baseline
  
  values_comparison <- samples %>% filter(NewCol==comparison[1])
  
  values_comparison <- values_comparison[variables_interest] %>% distinct()
  
  
  values_baseline <- samples %>% filter(NewCol==comparison[2])
  
  values_baseline <- values_baseline[variables_interest] %>% distinct()
  
  
  difference <- compare_columns(values_comparison, values_baseline)
  
  comparison_name <- paste0(difference, "_", pull(values_comparison[difference]), "_vs_", pull(values_baseline[difference]))
  
  print(paste0("The name of the comparison is ", comparison_name))
  print("Baseline values are:")
  
  for (var in variables_interest) {
    print(values_baseline[[var]])
  }
  
  # Rerun deseq2 with the correct baseline
  
  for (variable in variables_interest) {
    if (is.factor(values_baseline[[variable]])) {
      dds[[variable]] <- relevel(dds[[variable]], ref = as.character(values_baseline[[variable]]))
    } else {
      dds[[variable]] <- relevel(dds[[variable]], ref = values_baseline[[variable]])
    }
  }
  
  dds <- DESeq(dds)
  
  vsd <- varianceStabilizingTransformation(dds,blind=FALSE)
  vst <- assay(vsd)
  vst <- vst - min(vst)
  
  # Make list of samples that will be considered to calculate the cook distance
  relevant <- list() 
  
  relevant[[comparison[1]]] <- samples %>% filter(NewCol == comparison[1]) %>% select(SampleID) %>% pull()
  
  relevant[[comparison[2]]] <- samples %>% filter(NewCol == comparison[2]) %>% select(SampleID) %>% pull()
  
  
  # Apply the function and store the result in the list
  return(extract_results(dds=dds,
                         vst=vst,
                         contrast=str_replace_all(comparison_name, "-", "."),
                         relevant_samples = relevant,
                         ...
  )
  )
  
}
````


</details>

# Methods

The pre-processing was performed using the nfcore rnaseq pipeline v. 3.14.0, using the "--skip_alignment" and "--pseudo-alignment salmon" options.

# Results

## DESeq2

All output files can be found in the DE_results folder, where files ending in "genes.csv" contain gene list which have been filtered based on a FDR threshold of 0.01 and a minumum log2FC of 0.5.

This stringent threshold was chosen due to the high number of differentially expressed genes.

The files ending in "results.csv" contain all DE genes (without any filtering based on quality criteria). 

* Running the pipeline

````{r DEseq2, include=FALSE}
dds <- readRDS(file=here("data/analysis/salmon/dds_merged-tech-reps.rds"))

samples <- read_csv(here("doc/samples_merged-tech-reps.csv"),show_col_types = FALSE)

#Set the desired degisn
design(dds) <- formula(~ VARIABLE1 * VARIABLE2)

vsd <- varianceStabilizingTransformation(dds,blind=FALSE)
vst <- assay(vsd)
vst <- vst - min(vst)

dir.create(here("data/analysis/DE"),showWarnings=FALSE)
save(vst,file=here("data/analysis/DE/vst-aware.rda"))
write_delim(as.data.frame(vst) %>% rownames_to_column("ID"),
            here("data/analysis/DE/vst-aware.tsv"))

dds <- DESeq(dds)
resultsNames(dds)

````

<details><summary>Dispersion</summary>

The dispersion estimation is adequate.

````{r disp_est, fig.cap="Dispersion estimation"}
plotDispEsts(dds)
````

</details>

<details><summary>Results graphs per contrast</summary>

### Extracting results

Remember to remove suspicious DEGs from the results if you do not want to keep them

````{r contrasts}



#Reload dds object
dds <- readRDS(file=here("data/analysis/salmon/dds_merged-tech-reps.rds"))


# Use map to apply the function to each comparison
# INTEREST_COL is the name of a column with all the relevant information on a sample.
# variables_interest is a vector of column names with the names of all the columns included in the design.
# For example, if the design is "time * treatment", then the INTEREST_COL will be the name of a column containing values like:  time1_treatment1, time2_treatment1 and so on
# variables_interest will be instead a vector like this: c("time", "treatment")

# Example samplesheet
# Samp  | Time   | Treatment
# samp1 | spring | control
# samp2 | spring | drought
# samp3 | winter | control
# samp4 | winter | drought

# If the design is ~ Treatment, then Interest_Col is Treatment, and variables_interest is c("Treatment").
# Then the comparison is
# comparisons <- list(
#   c("drought",	"control"))
# It's recommended that the second element is the baseline, in this case = control

# If the design is ~ Time*Treatment, then you need to make a new column combining both together like
# Samp  | Time   | Treatment | Time_Treatment
# samp1 | spring | control   | spring_control
# samp2 | spring | drought   | spring_drought
# samp3 | winter | control   | winter_control
# samp4 | winter | drought   | winter_drought
# Then, Interest_Col is Time_Treatment, and variables_interest is c("Time","Treatment")
# Then the comparison is
# comparisons <- list(
#   c("spring_drought",	"spring_control"),
#   c("winter_drought",	"winter_control"),
#   c("spring_drought",	"winter_drought"))
# It's recommended that the second element is the baseline, in this case = spring_control, winter_control and winter_drought, respectively for our three comparisons

#Set the desired degisn
design(dds) <- formula(~ VARIABLE1 * VARIABLE2)

# Define your comparisons as a list of vectors, each with two values of INTEREST_COL that you wish to compare
comparisons <- list(
  c("Condition1",	"Condition2"),
  c("Condition1",	"Condition3"),
  c("Condition2",	"Condition3")
)


results_list <- map(comparisons, ~ process_comparison(.x, "INTEREST_COL", c("VARIABLE1", "VARIABLE2"), dds=dds, samples=samples, lfc=0.5, padj=0.01))


# Set names for the results list
names(results_list) <- map_chr(comparisons, function(comparison) {
  gsub(" ", "", paste(comparison, collapse="vs"))
})
  

````

### Group DEGs in a single table

````{r grouping}

path <- here("data/analysis/DE/")
  
# Get a list of all csv files in the directory
files <- list.files(path, pattern = "*genes.csv")

# Initialize an empty data frame
all_data <- data.frame()

# Loop through the files
for(file in files){
  # Read the csv file
  data <- read_csv(paste0(path, "/", file), show_col_types = FALSE)
  
  
  # Add a new column with the file name
  data$Comparison <- file
  
  # Bind the data to the existing data frame
  all_data <- bind_rows(all_data, data)
}

# Split the 'Comparison' column using 'vs' as the separator
split_data <- strsplit(all_data$Comparison, split = "vs")

# Extract 'interest' and 'control' values
all_data$interest <- sapply(split_data, function(x) sub("DE-", "", x[1]))
all_data$control <- sapply(split_data, function(x) sub("_genes.csv", "", x[2]))

# Rename the first column
colnames(all_data)[colnames(all_data) == "...1"] <- "Gene"

write_tsv(all_data, here("data/analysis/DE/All_DEGs.tsv"))


````

</details>

### DEGs number

This graph shows the number of differentially expressed genes in every situation.

````{r visualization}

library(reshape2)


# Convert the list of lists to a data frame
df <- do.call(rbind, lapply(seq_along(results_list), function(i) {
  data.frame(list = factor(names(results_list)[i], levels = names(results_list)),
             up = length(results_list[[i]]$up),
             dn = length(results_list[[i]]$dn))
}))

df_melt <- melt(df, id.vars = "list")

# Create the stacked bar plot

ggplot(df_melt, aes(x = list, y = value, fill = variable)) +
  geom_bar(stat = "identity") +
  labs(x = "Contrast", y = "Differentially expressed genes", fill="Differential expression") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

detach("package:reshape2", unload=TRUE)


````


### Venn diagrams to compare selected conditions
The names of the lists must be added manually
#### Upregulated genes {-}

````{r venn_up}
grid.newpage()

list_for_Venn <- list(results_list[["Group1vsControl"]]$up,
                      results_list[["Group1vsControl"]]$dn,
                      results_list[["Group2vsControl"]]$up,
                      results_list[["Group2vsControl"]]$dn)
                      
                      
grid.draw(venn.diagram(list_for_Venn,
                       NULL,
                       fill=pal[1:4],
                       category=c("Group1vsControl_up",
                                  "Group1vsControl_dn",
                                  "Group2vsControl_up",
                                  "Group2vsControl_dn"
)))
````


## GO enrichment
GO enrichment is run on all the groups of upregulated or downregulated genes, using a parent-child Fisher test with an FDR threshold of 0.05.


* Load functions
````{r load_functions}

prepAnnot <- function(mapping){
  annot <- read_delim(mapping,col_names=FALSE,show_col_types=FALSE)
  geneID2GO <- lapply(lapply(unlist(annot[,2],use.names=FALSE),strsplit,"\\|"),unlist)
  names(geneID2GO) <- unlist(annot[,1],use.names=FALSE)
  return(geneID2GO)
}

# the following function gets a vector of genes with baseMean >= the baseMean of the gene with lower expression with non NA padj
get_background <- function(results_file) {
  suppressMessages(
    data <- read_csv(results_file, show_col_types = FALSE)
  )
  data <- data %>% dplyr::rename(gene = ...1)
  thres <- min(data[!is.na(data$padj), ]$baseMean)
  genes <- data %>% 
    filter(baseMean >= thres) %>% 
    dplyr::select(gene) %>% 
    pull()
  return(genes)
}


#' The following function is like the TopGO function found in the TopGO template, but
#' it returns a single dataframe with all enriched GO terms, rather than a list of three
#' dataframes with enriched biological processes, molecular functions and cellular components.

topGO_combined <- function(set,background,annotation,
                  ontology=c("BP","CC","MF"),
                  algorithm="parentchild",
                  statistic="fisher",
                  p.adjust=sort(p.adjust.methods),
                  alpha=0.05,
                  getgenes=FALSE){
  
  p.adjust <- match.arg(p.adjust)
  
  # create the allGenes
  allGenes <- factor(as.integer(background %in% set))
  names(allGenes) <- background
  
  # iterate over the ontologies
  lst <- lapply(ontology, function(o,g,a){
    GOdata <- new("topGOdata", 
                  ontology = o, 
                  allGenes = g,
                  annot = annFUN.gene2GO, 
                  gene2GO = a)
    results <- runTest(GOdata,algorithm=algorithm,statistic=statistic)
    
    n <- ifelse(p.adjust=="none",
                sum(score(results) <= alpha),
                sum(p.adjust(score(results),method=p.adjust) <= alpha))
    
    if(n==0){
      return(NULL)
    } else{
      #I added "numChar=1000 to not trim the GO
      resultTable <- as_tibble(GenTable(GOdata,
                         results,
                         numChar=1000,
                         topNodes=n)) %>% 
        rename_with(function(sel){"FDR"},.cols=last_col())
      if(getgenes){
        resultTable <- resultTable %>%
          mutate(allgenes = map(GO.ID,function(x){allGO[[x]]})) %>%
          mutate(siggenes = map(allgenes,function(x){unlist(x)[unlist(x) %in% set]}))  %>%
          mutate(allgenes = map(allgenes,function(x){paste(x,collapse = "|")}) %>% unlist(use.names = F),
                 siggenes = map(siggenes,function(x){paste(x,collapse = "|")}) %>% unlist(use.names = F))
      }
      resultTable
    }
  },allGenes,annotation)
  names(lst) <- ontology
  #This last bind_rows was added by me and is not part of the original function
  return(bind_rows(lst, .id = "GO category"))
}


````

* Establish annotation and background

````{r prep_annotation}

mapping <- "/mnt/picea/storage/reference/Arabidopsis-thaliana/TAIR10/gopher/tair10_gene_to_go.tsv"
annotation <- prepAnnot(mapping)
files <- list.files(path = here("data/analysis/DE/"), pattern = "results\\.csv$", full.names=TRUE)

background <- map(files, get_background) %>% 
  unlist() %>% 
  base::unique()

````


* Calculate the enrichment
````{r enrichment}
library(topGO)
library(purrr)


# Making a list of the vectors I want to test for enrichment
# By default, the upregulated and downregulated genes from every contrast are tested.
res <- list()
for (name in names(results_list)) {
  res[[paste0(name, "_up")]] <- results_list[[name]]$up
  res[[paste0(name, "_dn")]] <- results_list[[name]]$dn
}


#Removing empty lists
res <- Filter(function(x) length(x) > 1, res)

# Apply topGO_combined to each element in res
results <- map(res, ~ topGO_combined(.x, background, annotation))

# Remove tibbles with 0 rows from results
results <- discard(results, ~ nrow(.x) == 0)

# Export each tibble in results to a TSV file
walk2(results, names(results), ~ write_tsv(.x, file = here(paste0("data/analysis/DE/GO-enr_", .y, ".tsv"))))





````

### Group GO enrichments in a single table

````{r grouping_enr}

path <- here("data/analysis/DE/")
  
# Get a list of all csv files in the directory
files <- list.files(path, pattern = "GO-enr.*.tsv")

# Initialize an empty data frame
all_data <- data.frame()

# Loop through the files
for(file in files){
  # Read the csv file
  data <- read_tsv(paste0(path, "/", file), show_col_types = FALSE)
  
  
  # Add a new column with the file name
  data$dataset <- file
  
  suppressMessages(
    data <- data %>%
    dplyr::mutate(FDR = ifelse(FDR == "< 1e-30", 0, FDR))
  )
  
  data$FDR <- as.numeric(data$FDR)
  
  # Bind the data to the existing data frame
  all_data <- bind_rows(all_data, data)
}



write_tsv(all_data, here("data/analysis/DE/All_DEGs_Enrichment.tsv"))


````

### GO enrichment wordclouds

Note that the wordclouds can sometimes not show some of the GO terms, if their names could not be fit to the page.

To see all the enriched terms it is better to check the original tables in the DE folder.


`r emoji("point_right")` **Most significantly enriched terms appear bigger in the wordclouds.**

</details>

<details><summary>Wordclouds</summary>

````{r wordclouds}
library(wordcloud)

for (name in names(results)) {
  
    print(paste0("Enriched GO terms in ", name))

  suppressMessages(
    data <- results[[name]] %>%
    dplyr::mutate(FDR = ifelse(FDR == "< 1e-30", "1e-30", FDR)) %>%
    dplyr::mutate(scores = -log10(as.numeric(FDR))) %>% 
                    dplyr::select(Term, scores)
  )


  wordcloud(words = data$Term, 
            freq = data$scores, 
            min.freq = 0,           
            max.words = 200, 
            random.order = FALSE, 
            rot.per = 0, 
            scale = c(2.4,.3),  
            colors = brewer.pal(8, "Dark2"))
  }
  


````
</details>
</details>

### GO enrichment dotplots

`r emoji("point_right")` **The following plots show the top 20 most significantly enriched GO terms for each of the lists of upregulated or downregulated genes.**


</details>

<details><summary>Dotplots</summary>

````{r dotplots}
ntop <- 20

for (name in names(results)) {
  
  suppressMessages(
    data <- results[[name]] %>%
    dplyr::mutate(FDR = parse_double(sub("<","",FDR))) %>%
    dplyr::mutate(scores = -log10(as.numeric(FDR))) %>% 
                    dplyr::select(Term, scores)
  )

  
  # Add this line to filter the top terms
  data <- data %>% dplyr::arrange(desc(scores)) %>% dplyr::slice(1:ntop)
  
  # Convert Term to a factor and specify the levels to be in the order of descending scores
  data$Term <- factor(data$Term, levels = data$Term[order(data$scores, decreasing = TRUE)])
  
p <- ggplot(data,
  aes(x = Term, y = scores, size = scores, fill = scores)) +
  expand_limits(y = 1) +
  geom_point(shape = 21) +
  scale_size(range = c(2.5,12.5), name="-log10(FDR)") +
  scale_fill_continuous(low = 'royalblue', high = 'red4', name="-log10(FDR)") +
  xlab('') +
  ylab('-log10(FDR)') +
  labs(
    title = paste0("Enriched GOs for result ", name),
    subtitle = paste('Top', ntop, 'terms ordered by adjustes pvalue'),
    caption = 'Cut-off lines drawn at equivalents of p=0.05, p=0.01, p=0.001') +
  geom_hline(yintercept = c(-log10(0.05), -log10(0.01), -log10(0.001)),
    linetype = c("dotted", "longdash", "solid"),
    colour = c("black", "black", "black"),
    size = c(0.5, 1.5, 3)) +
  theme_bw(base_size = 24) +
  theme(
    legend.position = 'right',
    legend.background = element_rect(),
    plot.title = element_text(angle = 0, size = 16, face = 'bold', vjust = 1),
    plot.subtitle = element_text(angle = 0, size = 14, face = 'bold', vjust = 1),
    plot.caption = element_text(angle = 0, size = 12, face = 'bold', vjust = 1),

    axis.text.x = element_text(angle = 0, size = 12, face = 'bold', hjust = 1.10),
    axis.text.y = element_text(angle = 0, size = 12, face = 'bold', vjust = 0.5),
    axis.title = element_text(size = 12, face = 'bold'),
    axis.title.x = element_text(size = 12, face = 'bold'),
    axis.title.y = element_text(size = 12, face = 'bold'),
    axis.line = element_line(colour = 'black'),

    #Legend
    legend.key = element_blank(), # removes the border
    legend.key.size = unit(1, "cm"), # Sets overall area/size of the legend
    legend.text = element_text(size = 14, face = "bold"), # Text size
    title = element_text(size = 14, face = "bold")) +
  coord_flip()

print(p)
}

# ggplot2::ggsave(here("analysis/GO/A_vs_B_Fisher.pdf"),
#                device = NULL,
#                height = 8.5,
#                width = 12)
````
</details>


**Below are plot from top 20 most significantly enriched GO terms in each category:**

* BP: Biological Process

* CC: Cellular Component

* MF: Molecular Function
 
</details>

<details><summary>Dotplots</summary>

````{r dotplots2}
ntop <- 20

iwalk(results, function(e,r){
  dat <- e %>%
    mutate(FDR = parse_double(sub("<","",FDR)),
           GeneRatio = Significant/Annotated,
           Count = as.numeric(Significant)) %>%
    group_by(`GO category`) %>%
    arrange(FDR) %>%
    slice(1:ntop) %>%
    ungroup() %>%
    mutate(Term = factor(Term, levels = Term[order(GeneRatio)]))
  p <- ggplot(dat, aes(x =Term, y = GeneRatio, color = FDR, size = Count)) + 
    geom_point() +
    scale_color_gradient(low = "red", high = "blue") +
    theme_bw() + 
    ylab("GeneRatio") + 
    xlab("") + 
    facet_grid(`GO category` ~ ., scales = "free", space = "free") +
    ggtitle(paste0(r, ": "," GO enrichment")) +
    coord_flip()
  plot(p)
})
````
</details>

## Session Info
<details><summary>Setup</summary>
 ````{r session info, echo=FALSE}
 sessionInfo()
 ````
</details>
