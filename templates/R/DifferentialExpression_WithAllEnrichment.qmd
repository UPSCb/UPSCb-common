---
title: "Differential expression"
author: "Edoardo Piombo"
date: "`r Sys.Date()`"
format: html
fig-width: 12
fig-height: 9
toc: true
number-sections: true
toc-depth: 3
toc-float:
  collapsed: TRUE
  smooth-scroll: TRUE
code-folding: hide
theme: "flatly"
highlight: pygments
includes:
  before-body: header.html
  after-body: footer.html
css: style.css
---

**This pipeline does not work for everyone at the moment. It uses reticulate to access a conda environment present only in certain accounts.**
**If you want to use this pipeline, ask Edoardo about how to make the conda environment.**



````{r opts, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
````

<details><summary>Setup</summary>

* Libraries

````{r }
suppressPackageStartupMessages({
    library(data.table)
    library(DESeq2)
    library(gplots)
    library(here)
    library(hyperSpec)
    library(RColorBrewer)
    library(emoji)
    library(tidyverse)
    library(VennDiagram)
})
````

* Helper files

````{r }
suppressMessages({
    source(here("UPSCb-common/Rtoolbox/src/plotEnrichedTreemap.R"))
    source(here("UPSCb-common/src/R/featureSelection.R"))
    source(here("UPSCb-common/src/R/volcanoPlot.R"))
})
````

* Graphics

````{r }
pal=brewer.pal(8,"Dark2")
hpal <- colorRampPalette(c("blue","white","red"))(100)
mar <- par("mar")
````

* Functions

  * Plot specific gene expression

````{r line_plot}
"line_plot" <- function(dds=dds,vst=vst,gene_id=gene_id){
    message(paste("Plotting",gene_id))
    sel <- grepl(gene_id,rownames(vst))
    stopifnot(sum(sel)==1)

    p <- ggplot(bind_cols(as.data.frame(colData(dds)),
                          data.frame(value=vst[sel,])),
                aes(x=Treatment,y=value,col=Treatment,group=Treatment)) +
        geom_point() + geom_smooth() +
        scale_y_continuous(name="VST expression") + 
        ggtitle(label=paste("Expression for: ",gene_id))
    
    suppressMessages(suppressWarnings(plot(p)))
    return(NULL)
}
````

  * Get suspicious genes
  
````{r get_suspicious_genes}
"get_suspicious_genes" <- function(vst,relevant_samples, threshold=10){
  
  vstdf <- as_tibble(vst[,unlist(relevant_samples)], rownames = "Gene")
  
    
    # Convert to long format for easier manipulation
vstdf_long <- vstdf %>%
  pivot_longer(cols = -Gene, names_to = "sample", values_to = "expression")


# Extract group information from relevant_samples list
group_info <- as_tibble(relevant_samples) %>% pivot_longer(names_to="group", values_to="sample", cols=everything()) %>% arrange(group)

#Add group information to vsdtdf_long
vstdf_long <- vstdf_long %>%
  left_join(group_info, by = "sample")


# First, I replace zeroes with values equal to half the minimum detected values.
# This high values of z-replacement is so genes with very low expression values and 1 or 2 zeroes do not come up as suspicious
# Calculate the minimum non-zero value in the expression column
min_non_zero <- min(vstdf_long$expression[vstdf_long$expression > 0])

# Define the low value as a small fraction of the minimum non-zero value
low_value <- min_non_zero * 0.5  # Adjust the fraction as needed



# Function to calculate the required values
  results <- vstdf_long %>%
  mutate(expression = ifelse(expression == 0, low_value, expression)) %>% 
    group_by(Gene, group) %>%
    summarise(
    max_expr = max(expression),
    min_expr = min(expression),
    avg_expr = mean(expression),
    max_div_avg = max(expression) / mean(expression[expression != max(expression)]),
    avg_non_min = mean(expression[expression != min(expression)]),
    min_div_avg = avg_non_min / min(expression)
  ) %>%
  ungroup() %>%  
    #As genes with only 0 values were returning NA in the max_div_avg and min_div_avg columns, I replace this values with 1
    mutate_all(~replace_na(., 1))


#In the end I only use max_div_avg to determine suspicious genes
  suspicious_genes  <- results %>% 
  filter(max_div_avg > threshold) %>% 
  select(Gene) %>%
  distinct() %>% 
  pull()


return(suspicious_genes)
  
}
```` 

  * Load function to find out the name of columns not identical in two dataframes
  
````{r compare_columns}

compare_columns <- function(tibble1, tibble2) {
  # Initialize an empty vector to store names of non-identical columns
  non_identical_columns <- c()
  
  # Loop through each column in tibble1
  for (col in colnames(tibble1)) {
    # Check if the column exists in tibble2
    if (col %in% colnames(tibble2)) {
      # Compare the columns
      if (!all(tibble1[[col]] == tibble2[[col]])) {
        # If not identical, add the column name to the vector
        non_identical_columns <- c(non_identical_columns, col)
      }
    } else {
      # If the column does not exist in tibble2, add the column name to the vector
      non_identical_columns <- c(non_identical_columns, col)
    }
  }
  
  return(non_identical_columns)
}
````


  * Extract the DE results. Default cutoffs are from Schurch _et al._, RNA, 2016

````{r function_extract_results}
"extract_results" <- function(dds,vst,contrast, relevant_samples,
                              padj=0.01,lfc=0.5,
                              plot=TRUE,verbose=TRUE,
                              export=TRUE,default_dir=here("data/analysis/DE"),
                              default_prefix="DE-",
                              labels=colnames(dds),
                              sample_sel=1:ncol(dds),
                              cooks_division = 1,
                              optimize_cook = FALSE,
                              expression_cutoff=0,
                              debug=FALSE,filter=c("median",NULL),...){
    
    # get the filter
    if(!is.null(match.arg(filter))){
        filter <- rowMedians(counts(dds,normalized=TRUE))
        message("Using the median normalized counts as default, set filter=NULL to revert to using the mean")
    }
  
    # Determining default cooks cutoff
    m <- ncol(counts(dds))

    p <- ncol(model.matrix(design(dds), colData(dds)))

    cooks_cutoff <- qf(0.99, p, m - p)

    # Setting a cooks cutoff equal to the defualt, divided by the cooks_division parameter

    # validation
    if(length(contrast)==1){
        res <- results(dds,name=contrast,filter = filter, cooksCutoff = cooks_cutoff/cooks_division)
    } else {
        res <- results(dds,contrast=contrast,filter = filter, cooksCutoff = cooks_cutoff/cooks_division)
    }
  
  if (optimize_cook == TRUE) {
    
    suspicious <- get_suspicious_genes(vst, relevant_samples, threshold=10)
    
    thres <- padj
    
    while (cooks_division < 10 &&
      as_tibble(res, rownames="Gene") %>% 
           filter(Gene %in% suspicious) %>% 
           filter(log2FoldChange > 0.5 | log2FoldChange < -0.5) %>% 
           filter(!is.na(padj)) %>% 
           filter(padj < thres) %>% 
           select(Gene) %>% 
           pull() %>% 
           length() > 0 )
    {
      cooks_division <- cooks_division + 1
          if(length(contrast)==1){
        res <- results(dds,name=contrast,filter = filter, cooksCutoff = cooks_cutoff/cooks_division)
    } else {
        res <- results(dds,contrast=contrast,filter = filter, cooksCutoff = cooks_cutoff/cooks_division)
    }
    }
    
    
    
  }
    
    print(paste0("Final cooks_division values is ", cooks_division, ", corresponding to a cooks cutoff values of ", cooks_cutoff/cooks_division))
  
  
    
    stopifnot(length(sample_sel)==ncol(vst))
    
    if(plot){
        par(mar=c(5,5,5,5))
        volcanoPlot(res)
        par(mar=mar)
    }
    
    # a look at independent filtering
    if(plot){
        plot(metadata(res)$filterNumRej,
             type="b", ylab="number of rejections",
             xlab="quantiles of filter")
        lines(metadata(res)$lo.fit, col="red")
        abline(v=metadata(res)$filterTheta)
    }
    
    if(verbose){
        message(sprintf("The independent filtering cutoff is %s, removing %s of the data",
                        round(metadata(res)$filterThreshold,digits=5),
                        names(metadata(res)$filterThreshold)))
        
        max.theta <- metadata(res)$filterNumRej[which.max(metadata(res)$filterNumRej$numRej),"theta"]
        message(sprintf("The independent filtering maximises for %s %% of the data, corresponding to a base mean expression of %s (library-size normalised read)",
                        round(max.theta*100,digits=5),
                        round(quantile(counts(dds,normalized=TRUE),probs=max.theta),digits=5)))
    }
    
    if(plot){
        qtl.exp=quantile(counts(dds,normalized=TRUE),probs=metadata(res)$filterNumRej$theta)
        dat <- data.frame(thetas=metadata(res)$filterNumRej$theta,
                          qtl.exp=qtl.exp,
                          number.degs=sapply(lapply(qtl.exp,function(qe){
                              res$padj <= padj & abs(res$log2FoldChange) >= lfc & 
                                  ! is.na(res$padj) & res$baseMean >= qe
                          }),sum))
        if(debug){
            plot(ggplot(dat,aes(x=thetas,y=qtl.exp)) + 
                     geom_line() + geom_point() +
                     scale_x_continuous("quantiles of expression") + 
                     scale_y_continuous("base mean expression") +
                     geom_hline(yintercept=expression_cutoff,
                                linetype="dotted",col="red"))
        
            p <- ggplot(dat,aes(x=thetas,y=qtl.exp)) + 
                geom_line() + geom_point() +
                scale_x_continuous("quantiles of expression") + 
                scale_y_log10("base mean expression") + 
                geom_hline(yintercept=expression_cutoff,
                           linetype="dotted",col="red")
            suppressMessages(suppressWarnings(plot(p)))
            
            plot(ggplot(dat,aes(x=thetas,y=number.degs)) + 
                     geom_line() + geom_point() +
                     geom_hline(yintercept=dat$number.degs[1],linetype="dashed") +
                     scale_x_continuous("quantiles of expression") + 
                     scale_y_continuous("Number of DE genes"))
            
            plot(ggplot(dat,aes(x=thetas,y=number.degs[1] - number.degs),aes()) + 
                     geom_line() + geom_point() +
                     scale_x_continuous("quantiles of expression") + 
                     scale_y_continuous("Cumulative number of DE genes"))
            
            plot(ggplot(data.frame(x=dat$thetas[-1],
                                   y=diff(dat$number.degs[1] - dat$number.degs)),aes(x,y)) + 
                     geom_line() + geom_point() +
                     scale_x_continuous("quantiles of expression") + 
                     scale_y_continuous("Number of DE genes per interval"))
            
            plot(ggplot(data.frame(x=dat$qtl.exp[-1],
                                   y=diff(dat$number.degs[1] - dat$number.degs)),aes(x,y)) + 
                     geom_line() + geom_point() +
                     scale_x_continuous("base mean of expression") + 
                     scale_y_continuous("Number of DE genes per interval"))
            
            p <- ggplot(data.frame(x=dat$qtl.exp[-1],
                                   y=diff(dat$number.degs[1] - dat$number.degs)),aes(x,y)) + 
                geom_line() + geom_point() +
                scale_x_log10("base mean of expression") + 
                scale_y_continuous("Number of DE genes per interval") + 
                geom_vline(xintercept=expression_cutoff,
                           linetype="dotted",col="red")
            suppressMessages(suppressWarnings(plot(p)))
        }
    }
    
    sel <- res$padj <= padj & abs(res$log2FoldChange) >= lfc & ! is.na(res$padj) & 
        res$baseMean >= expression_cutoff
    
    if(verbose){
      message(sprintf(paste(
        ifelse(sum(sel)==1,
               "There is %s gene that is DE",
               "There are %s genes that are DE"),
        "with the following parameters: FDR <= %s, |log2FC| >= %s, base mean expression > %s"),
        sum(sel),padj,
        lfc,expression_cutoff))
    }
    
        # proceed only if there are DE genes
    if(sum(sel) > 0){
        val <- rowSums(vst[sel,sample_sel,drop=FALSE])==0
        if (sum(val) >0){
          warning(sprintf(paste(
            ifelse(sum(val)==1,
                   "There is %s DE gene that has",
                   "There are %s DE genes that have"),
            "no vst expression in the selected samples"),sum(val)))
          sel[sel][val] <- FALSE
        } 

        if(export){
            if(!dir.exists(default_dir)){
                dir.create(default_dir,showWarnings=FALSE,recursive=TRUE,mode="0771")
            }
            write.csv(res,file=file.path(default_dir,paste0(default_prefix,"_results.csv")))
            write.csv(res[sel,],file.path(default_dir,paste0(default_prefix,"_genes.csv")))
        }
        par(mar=c(0,5,5,5)+0.1)
        if(plot & sum(sel)>1){
            heatmap.2(t(scale(t(vst[sel,sample_sel]))),
                      distfun = pearson.dist,
                      hclustfun = function(X){hclust(X,method="ward.D2")}, dendrogram='row',  Rowv=TRUE,
                      trace="none",col=hpal,labRow = FALSE, srtCol = 45, margin=c(6,6),
                      labCol=labels[sample_sel],...
            )
        }
    }
    return(list(all=rownames(res[sel,]),
                up=rownames(res[sel & res$log2FoldChange > 0,]),
                dn=rownames(res[sel & res$log2FoldChange < 0,])))
}
````


* Apply extract results in a contrast-dependent manner

````{r apply_extract_results}

# variables_interest must be a vector containing all the names of column in samples containing variables across which the comparisons will run.

# For example, if you plan to run comparisons across Treatment and Time, then variables_interest shoulc be c("Treatment", "Time")

# NameConditionColumn must be the column from which you will pull the values to specify your comparison.
# For example, if the comparison is c("T0_treated", "T0_control"), then NameConditionColumn will need to specify which samples belong to each of these two groups.



"apply_extract_results" <- function(comparison,
                                    samples,
                                    variables_interest,
                                    NameConditionColumn,
                                    dds,
                                    vst,
                              padj=0.01,lfc=0.5,
                              plot=TRUE,verbose=TRUE,
                              export=TRUE,default_dir=here("data/analysis/DE"),
                              default_prefix="DE-",
                              labels=colnames(dds),
                              sample_sel=1:ncol(dds),
                              cooks_division = 1,
                              optimize_cook = TRUE,
                              expression_cutoff=0,
                              debug=FALSE,filter=c("median",NULL),...)
{



  
  print(gsub(" ", "", paste(comparison, collapse="vs")))
  
  #Make a new column whose value is equal to NameConditionColumn
  
  samples$NewCol <- samples[[NameConditionColumn]]
  
  # Determine the correct baseline
  
  values_comparison <- samples %>% filter(NewCol==comparison[1])
  
  values_comparison <- values_comparison[variables_interest] %>% distinct()

  
  values_baseline <- samples %>% filter(NewCol==comparison[2])
  
  values_baseline <- values_baseline[variables_interest] %>% distinct()

  
  difference <- compare_columns(values_comparison, values_baseline)
  
  comparison_name <- paste0(difference, "_", pull(values_comparison[difference]), "_vs_", pull(values_baseline[difference]))
  
  print(paste0("The name of the comparison is ", comparison_name))
  print("Baseline values are:")
  
  for (var in variables_interest) {
    print(values_baseline[[var]])
  }

  # Rerun deseq2 with the correct baseline
  
  for (variable in variables_interest)
{
  dds[[variable]] <- relevel(dds[[variable]], ref = values_baseline[[variable]])
  }
  

  dds <- DESeq(dds)
  
  vsd <- varianceStabilizingTransformation(dds,blind=FALSE)
  vst <- assay(vsd)
  vst <- vst - min(vst)
  
  # Make list of samples that will be considered to calculate the cook distance
  relevant <- list() 
  
  relevant[[comparison[1]]] <- samples %>% filter(NewCol %in% comparison[1]) %>% select(SampleID) %>% pull()
  
  relevant[[comparison[2]]] <- samples %>% filter(NewCol %in% comparison[2]) %>% select(SampleID) %>% pull()
  
  
  # Apply the function and store the result in the list
  return(extract_results(dds=dds,
                          vst=vst,
                         contrast=comparison_name,
                         lfc= lfc,
                         padj=padj,
                         relevant_samples = relevant,
                         plot=plot,verbose=verbose,
                              export=export,default_dir=default_dir,
                              default_prefix=default_prefix,
                              labels=labels,
                              sample_sel=sample_sel,
                              cooks_division = cooks_division,
                              optimize_cook = optimize_cook,
                              expression_cutoff=expression_cutoff,
                              debug=debug,filter=filter
                         )
  )
  
}
````


</details>

# Methods

The pre-processing was performed using the nfcore rnaseq pipeline v. 3.14.0, using the "--skip_alignment" and "--pseudo-alignment salmon" options.

# Results

## DESeq2

All output files can be found in the DE_results folder, where files ending in "genes.csv" contain gene list which have been filtered based on a FDR threshold of 0.01 and a minumum log2FC of 1.5.

This stringent threshold was chosen due to the high number of differentially expressed genes.

The files ending in "results.csv" contain all DE genes (without any filtering based on quality criteria). 

* Running the pipeline

````{r DEseq2}
dds <- readRDS(file=here("data/analysis/salmon/dds_merged-tech-reps.rds"))

samples <- read_csv(here("doc/samples_merged-tech-reps.csv"),show_col_types = FALSE)

#Set the desired degisn
design(dds) <- formula(~ Variable1 * Variable2)

vsd <- varianceStabilizingTransformation(dds,blind=FALSE)
vst <- assay(vsd)
vst <- vst - min(vst)

dir.create(here("data/analysis/DE"),showWarnings=FALSE)
save(vst,file=here("data/analysis/DE/vst-aware.rda"))
write_delim(as.data.frame(vst) %>% rownames_to_column("ID"),
            here("data/analysis/DE/vst-aware.tsv"))

dds <- DESeq(dds)
resultsNames(dds)
````

<details><summary>Dispersion</summary>

The dispersion estimation is adequate.

````{r disp_est, fig.cap="Dispersion estimation"}
plotDispEsts(dds)
````

</details>

<details><summary>Results graphs per contrast</summary>

### Extracting results
````{r contrasts}
# Define your comparisons as a list of vectors, each with two values of InterestCol that you wish to compare
comparisons <- list(
  c("Condition1",	"Condition2"),
  c("Condition1",	"Condition3"),
  c("Condition2",	"Condition3")
)

#Reload dds object
dds <- readRDS(file=here("data/analysis/salmon/dds_merged-tech-reps.rds"))

#Set the desired degisn
design(dds) <- formula(~ Variable1 * Variable2)


# Initialize an empty list to store all result objects
results_list <- list()


# Use map to apply the function to each comparison
process_comparison <- function(comparison) {
  result_name <- gsub(" ", "", paste(comparison, collapse="vs"))
  
  result <- apply_extract_results(
    comparison = comparison,
    samples = samples,
    variables_interest = c("Variable1", "Variable2"),
    Name_Condition_Column = "Condition",
    dds = dds,
    vst = vst,
    default_prefix = paste0("DE-", result_name, "_")
  )
  
  up <- tibble(Gene = result$up)
  down <- tibble(Gene = result$dn)
  
  write_tsv(up, here(paste0("data/analysis/DE/DE-", result_name, "_UP.tsv")), col_names = FALSE)
  write_tsv(down, here(paste0("data/analysis/DE/DE-", result_name, "_DOWN.tsv")), col_names = FALSE)
  
  return(result)
}

# Set names for the results list
names(results_list) <- map_chr(comparisons, function(comparison) {
  gsub(" ", "", paste(comparison, collapse="vs"))
})


````

### Group DEGs in a single table

````{r grouping}

path <- here("data/analysis/DE/")
  
# Get a list of all csv files in the directory
files <- list.files(path, pattern = "*genes.csv")

# Initialize an empty data frame
all_data <- data.frame()

# Loop through the files
for(file in files){
  # Read the csv file
  data <- read_csv(paste0(path, "/", file))
  
  
  # Add a new column with the file name
  data$Comparison <- file
  
  # Bind the data to the existing data frame
  all_data <- bind_rows(all_data, data)
}

# Split the 'Comparison' column using 'vs' as the separator
split_data <- strsplit(all_data$Comparison, split = "vs")

# Extract 'interest' and 'control' values
all_data$interest <- sapply(split_data, function(x) sub("DE-", "", x[1]))
all_data$control <- sapply(split_data, function(x) sub("_genes.csv", "", x[2]))

# Rename the first column
colnames(all_data)[colnames(all_data) == "...1"] <- "Gene"

write_tsv(all_data, here("data/analysis/DE/All_DEGs.tsv"))


````


</details>

### DEGs number

This graph shows the number of differentially expressed genes in every situation.

````{r visualization}

library(reshape2)


# Convert the list of lists to a data frame
df <- do.call(rbind, lapply(seq_along(results_list), function(i) {
  data.frame(list = factor(names(results_list)[i], levels = names(results_list)),
             up = length(results_list[[i]]$up),
             dn = length(results_list[[i]]$dn))
}))

df_melt <- melt(df, id.vars = "list")

# Create the stacked bar plot

ggplot(df_melt, aes(x = list, y = value, fill = variable)) +
  geom_bar(stat = "identity") +
  labs(x = "Contrast", y = "Differentially expressed genes", fill="Differential expression") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

detach("package:reshape2", unload=TRUE)


````




## Functional enrichment
Functional enrichment was run on all the groups of upregulated or downregulated genes, using a parent-child Fisher test with an FDR threshold of 0.05.

The table with the names and codes of the enriched GOs can be found in the DE_results folder.

* Load functions
````{r load_functions}

prepAnnot <- function(mapping){
  annot <- read_delim(mapping,col_names=FALSE,show_col_types=FALSE)
  geneID2GO <- lapply(lapply(unlist(annot[,2],use.names=FALSE),strsplit,"\\|"),unlist)
  names(geneID2GO) <- unlist(annot[,1],use.names=FALSE)
  return(geneID2GO)
}

# the following function gets a vector of genes with baseMean >= the one of the gene with lower expression with non NA padj
get_background <- function(results_file) {
  suppressMessages(
    data <- read_csv(results_file, show_col_types = FALSE)
  )
  data <- data %>% rename(gene = ...1)
  thres <- min(data[!is.na(data$padj), ]$baseMean)
  genes <- data %>% 
    filter(baseMean >= thres) %>% 
    dplyr::select(gene) %>% 
    pull()
  return(genes)
}

````

* Establish annotation and background

````{r prep_annotation}

#Here you should load files with the type of functional annotation that you want to test for enrichment
mappingGO <- here("reference/gopher/gene_to_go.tsv")
mappingEC <- here("reference/gopher/gene_to_kegg.tsv")
mappingPFAM <- here("reference/gopher/gene_to_pfam.tsv")


#Here, you can load as many different annotations you want (GO, KEGG, IPR, ecc...)

annotationGO <- prepAnnot(mappingGO)
annotationGO <- annotationGO %>% 
  enframe(name = "Gene", value = "Terms") %>% 
  unnest(Terms)

annotationEC <- prepAnnot(mappingEC)
annotationEC <- annotationEC %>% 
  enframe(name = "Gene", value = "Terms") %>% 
  unnest(Terms)

annotationPFAM <- prepAnnot(mappingPFAM)
annotationPFAM <- annotationPFAM %>% 
  enframe(name = "Gene", value = "Terms") %>% 
  unnest(Terms)

# All annotations must be exported to a file, and you must save a list with the name and file of each annotation

annotations = list(annotationGO, annotationEC, annotationPFAM)
names(annotations) <- c("GO", "EC", "PFAM")
for (annotation in names(annotations)) {
  write_tsv(annotations[[annotation]], here(paste0("data/analysis/DE/", annotation, ".txt")), col_names = FALSE)
  annotations[[annotation]] <- here(paste0("data/analysis/DE/", annotation, ".txt"))
}


#Now we get as background all genes not excluded by the independent filtering step of DESeq2
files <- list.files(path = here("data/analysis/DE/"), pattern = "results\\.csv$", full.names=TRUE)

background <- map(files, get_background) %>% 
  unlist() %>% 
  base::unique()
#The list of background genes must also be exported
write(background, here("data/analysis/DE/background.txt"))


#I make new folders that will be needed afterwards
dir.create(here("data/analysis/DE/lists_DEGs"),showWarnings=FALSE)
dir.create(here("data/analysis/DE/Enrichment_results"),showWarnings=FALSE)

````


*Initialise reticulare to run enrichment analysis in python
````{r initialise_reticulate}

library(reticulate)
use_condaenv("enrichment_reticulate", required = TRUE)

pybackground = r_to_py(background)

pyannotations = r_to_py(annotations)

pylists = r_to_py(results_list)


````


*Calculate the enrichment
```{python}


pylists = r.pylists
pyannotations = r.pyannotations

import func_e.vocabs.all as vocabs
import pandas as pd
from func_e.FUNC_E import FUNC_E
from pyhere import here


#First, let's import the term categories we are interested in
#Only the following three annotations are default, if you are working with other ones, you must import them through a dataframe (https://github.com/SystemsGenetics/FUNC-E)
terms = vocabs.getTerms(['GO', 'IPR', 'KEGG'])

#Example, here I add the EC AND PFAM annotationS to the default ones:
EC_terms = pd.read_csv(here("../Terms_databases_for_enrichment/EC_codes_terms.txt"), sep='\t')
EC_terms.fillna("", inplace=True)

PFAM_terms = pd.read_csv(here("../Terms_databases_for_enrichment/PFAM_terms.txt"), sep='\t')
PFAM_terms.fillna("", inplace=True)



# Concatenate the terms dataframes vertically
terms = pd.concat([terms, EC_terms], axis=0)

# Reset the index of the new dataframe
terms.reset_index(drop=True, inplace=True)

# First, we make a loop going through all the lists of genes that we want to test for enrichment, and we export them.

results = {}
for genes in list(pylists.keys()):
  for condition in ["up", "dn"]:
    
    dataset = pylists[genes][condition]
    with open(here(f"data/analysis/DE/lists_DEGs/list_genes_{genes}_{condition}.txt"), 'w') as f:
      f.write('\n'.join(dataset))
    
    dataset_file = here(f"data/analysis/DE/lists_DEGs/list_genes_{genes}_{condition}.txt")
      
    # Next, instantiating a new FUNC_E object, once for each list of genes of interest
    fe = FUNC_E()

    # Next, you need to set the p-value cutoff for enrichment testing:
    
    fe.setEnrichmentSettings({
        'ecut': 0.01
    })
    
    # If you desire, you can change the clustering default settings as well:
    
    fe.setClusteringSettings({
        'similarity_term_overlap': 3,
        'percent_similarity': 0.50,
        'initial_group_membership': 3,
        'multiple_linkage_threshold': 0.50,
        'final_group_membership':  3,
        'similarity_threshold': 0.5
    })
    
    
    # Next, FUNC_E can import the files needed for enrichment analysis. These are the same as the example files used in the command-line example above.
    # Here you can also load all the annotations you want to test for enrichment (GOs, KEGG, IPR, ecc...)
    # It is also possible to load entire new terms sets (Pfams, for example) (https://github.com/SystemsGenetics/FUNC-E)
    annotation_files = list(pyannotations.values())
    
    fe.importFiles({
       'background': here("data/analysis/DE/background.txt"),
       'query': dataset_file,
       'terms2features': annotation_files
    })
    
    fe.setTerms(terms)
    
    
    fe.run(cluster=False)
    
    if len(fe.enrichment) > 0:
      results[f"{genes}_{condition}"] = fe.enrichment
      for category in fe.enrichment["ID_Space"].drop_duplicates().tolist():
        number = len(fe.enrichment[fe.enrichment["ID_Space"]==category])
      print(f"{number} {category} terms were enriched in {genes}_{condition}")
      
    else:
      print(f"No enrichment calculated for genes in {genes}_{condition}")



```

```{r retrieve_results}
enrichdf = py_to_r(py$results)

#Now I save the results in separate files, depending on wich used annotations resulted in enrichments
for (name in names(enrichdf)) {
  enrichments <- enrichdf[[name]] %>% dplyr::select(ID_Space) %>% unique() %>% pull()
  for (enrichment in enrichments) {
    data <- enrichdf[[name]] %>%
      dplyr::filter(ID_Space == enrichment) %>% 
      dplyr::select(-Module)
    
    write_tsv(data, here(paste0("data/analysis/DE/Enrichment_results/", enrichment, "_enriched_", name, ".tsv")))
    
  }
}
```

### Group enrichment results in a single table

````{r grouping_enr}

library(purrr)

combined_enrich <- enrichdf %>%
  imap(~mutate(.x, dataset = .y)) %>%
  bind_rows() %>% 
  select(-Module)


write_tsv(combined_enrich, here("data/analysis/DE/Enrichment_results/All_DEGs_Enrichment.tsv"))


````

### Functional enrichment wordclouds

Note that the wordclouds can sometimes not show some of the GO terms, if their names could not be fit to the page.

To see all the enriched terms it is better to check the original tables in the DE folder.


`r emoji("point_right")` **Most significantly enriched terms appear bigger in the wordclouds.**

</details>

<details><summary>Wordclouds</summary>

````{r wordclouds}
library(wordcloud)

for (name in names(enrichdf)) {
  enrichments <- enrichdf[[name]] %>% dplyr::select(ID_Space) %>% unique() %>% pull()
  for (enrichment in enrichments) {
    print(paste0("Enriched ", enrichment, " terms in ", name))

  suppressMessages(
    data <- enrichdf[[name]] %>%
      dplyr::filter(ID_Space == enrichment) %>% 
    dplyr::mutate(scores = -log10(as.numeric(Benjamini))) %>% 
                    dplyr::select(Name, scores)
  )


  wordcloud(words = data$Name, 
            freq = data$scores, 
            min.freq = 0,           
            max.words = 200, 
            random.order = FALSE, 
            rot.per = 0, 
            scale = c(2.4,.3),  
            colors = brewer.pal(8, "Dark2"))
  }
}


````
</details>
</details>

### Functional enrichment dotplots

The following plots show the top 20 most significantly enriched GO terms for each of the lists of upregulated or downregulated genes.

</details>

<details><summary>Dotplots</summary>

```{r dotplots}
ntop <- 20

for (name in names(enrichdf)) {
  enrichments <- enrichdf[[name]] %>% dplyr::select(ID_Space) %>% unique() %>% pull()
  for (enrichment in enrichments) {
    print(paste0("Enriched ", enrichment, " terms in ", name))

  suppressMessages(
    data <- enrichdf[[name]] %>%
      dplyr::filter(ID_Space == enrichment) %>% 
    dplyr::mutate(scores = -log10(as.numeric(Benjamini))) %>% 
                    dplyr::select(Name, scores) %>%
      dplyr::arrange(desc(scores)) %>%
      dplyr::slice(1:ntop)
  )

  # The next line removes duplicates in the Name column, keeping for each of them only the one with the highest score
  data <- data %>%
  group_by(Name) %>%
  slice(which.max(scores))
  
  # Add this line to filter the top terms
  data <- data %>% dplyr::arrange(desc(scores)) %>% dplyr::slice(1:ntop)
  
  # Convert Name to a factor and specify the levels to be in the order of descending scores
  data$Term <- factor(data$Name, levels = data$Name[order(data$scores, decreasing = TRUE)])
  
p <- ggplot(data,
  aes(x = Name, y = scores, size = scores, fill = scores)) +
  expand_limits(y = 1) +
  geom_point(shape = 21) +
  scale_size(range = c(2.5,12.5), name="-log10(FDR)") +
  scale_fill_continuous(low = 'royalblue', high = 'red4', name="-log10(FDR)") +
  xlab('') +
  ylab('-log10(FDR)') +
  labs(
    title = paste0("Enriched terms for result ", name),
    subtitle = paste('Top', ntop, 'terms ordered by adjustes pvalue'),
    caption = 'Cut-off lines drawn at equivalents of p=0.05, p=0.01, p=0.001') +
  geom_hline(yintercept = c(-log10(0.05), -log10(0.01), -log10(0.001)),
    linetype = c("dotted", "longdash", "solid"),
    colour = c("black", "black", "black"),
    size = c(0.5, 1.5, 3)) +
  theme_bw(base_size = 24) +
  theme(
    legend.position = 'right',
    legend.background = element_rect(),
    plot.title = element_text(angle = 0, size = 16, face = 'bold', vjust = 1),
    plot.subtitle = element_text(angle = 0, size = 14, face = 'bold', vjust = 1),
    plot.caption = element_text(angle = 0, size = 12, face = 'bold', vjust = 1),

    axis.text.x = element_text(angle = 0, size = 12, face = 'bold', hjust = 1.10),
    axis.text.y = element_text(angle = 0, size = 12, face = 'bold', vjust = 0.5),
    axis.title = element_text(size = 12, face = 'bold'),
    axis.title.x = element_text(size = 12, face = 'bold'),
    axis.title.y = element_text(size = 12, face = 'bold'),
    axis.line = element_line(colour = 'black'),

    #Legend
    legend.key = element_blank(), # removes the border
    legend.key.size = unit(1, "cm"), # Sets overall area/size of the legend
    legend.text = element_text(size = 14, face = "bold"), # Text size
    title = element_text(size = 14, face = "bold")) +
  coord_flip()

print(p)
  }
}

# ggplot2::ggsave(here("analysis/GO/A_vs_B_Fisher.pdf"),
#                device = NULL,
#                height = 8.5,
#                width = 12)
```

</details>

## Session Info
<details><summary>Setup</summary>
 ````{r session info, echo=FALSE}
 sessionInfo()
 ````
</details>