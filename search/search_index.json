{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>On these pages you will find basic information about the bio-info facility's infrastructure and how to properly use it to ensure minimum disruptions and maximum productivity.  This page also acts as a library of common scripts and templates created to avoid reinventing the wheel then and again. This resource assumes no prior user experience with bioinformatic tools and resources. If you are familiar with the tools and resources, great, if not, please visit the Resources tab.</p>"},{"location":"#please-use-the-menu-on-the-left-to-navigate-or-use-the-search-bar-to-find-relevant-information","title":"Please use the menu on the left to navigate or use the search bar to find relevant information.","text":""},{"location":"#citation","title":"CITATION","text":"<p>Please use  to cite the use of these repos :-)</p>"},{"location":"#important-notice","title":"IMPORTANT NOTICE","text":"<p>2022/12/06 I found a serious bug in the DE template! I have corrected the DE template: https://github.com/UPSCb/UPSCb-common/tree/master/templates/R, but please check out your analysis done since 2021/03/05. Sadly, it means that any analysis needs redoing! :disappointed: :disappointed: :disappointed: The issue is that the template used the lfcThreshold when retrieving the DE results (using the DESeq2 results function). What this does, unlike the alpha parameter that sets the FDR threshold to return results, is to change the test that is being done. Instead of comparing for a difference in expression of 0, it tests for a difference in expression at the selected value (+0.5 by default). Results are likely to be quite drastically different!</p>"},{"location":"#contact-us","title":"Contact us","text":"<p>For UPSC members, ask us to be added to our Slack channel as well as mailing list. These are the two channels we use to communicate about server updates and downtime (as well as other technical issues), but also those we use to discuss projects, provide support, etc.</p>"},{"location":"2.%20Onboarding/","title":"Onboarding","text":"<p>These instructions are specific to the users at the Ume\u00e5 Plant Science Centre, you are welcome to get inspired by them though.</p>"},{"location":"2.%20Onboarding/#access","title":"Access","text":"<p>Your data analysis journey starts with you contacting us regarding your project to discuss how much storage and computing power you might need. We have quotas with storage limited to 1000GB/project and 50GB/user which often means that the end user (you) need to be well versed with good practices for resource management.</p> <p>After you have contact us, we will set up your account and we will ask you to follow the instructions seen in this video to finish setting up your account.</p> <p>Note</p> <p>We use key based authentication for access to the servers. Once your key has been authenticated you do not need password to access the server. However, access to R-Studio is password protected. You will get a password from us which you can use for initial log-in. Changing your password after the first log-in is recommended. </p>  To change your password follow these steps on your terminal or PowerShell  <pre><code>ssh &lt;username&gt;@micro\npasswd\n-Enter current password-\n-Enter New Password-\n-Confirm New Password-\n</code></pre>"},{"location":"2.%20Onboarding/#setup-your-project","title":"Setup your project","text":"<p>Before you start analysing data make sure to get familiar with the Resources at your disposal. In addition to the information on that page, know that we use <code>git</code> and <code>SLURM</code> to ensure reproducible research, here are gists on how to use them in your projects:</p> <ol> <li>Git setup</li> <li>SLURM usage</li> </ol> <p>We recommend you watch this video of a tech seminar (duration ~1h) on how to set up your project. Here are some key moments from the video:</p> <ul> <li>One of the first things to do after you have access to our servers is to copy the UPSCb-common GitHub repository in yor home directory on the server. This repository contains most basic scripts and utilities you will need to analyse your data. Steps to clone the repository are in the video starting here</li> <li>Using ssh keys with your GitHub account &gt; here</li> <li>Introduction to <code>SLURM</code> and how to use it &gt; here</li> </ul> <p>While this video uses R-Studio as an example, you can use VSCode as a substitute. </p>"},{"location":"2.%20Onboarding/#server-usage","title":"Server usage","text":"<p>A comprehensive guide outlining how to access and use our servers properly is here</p> <p>Warning</p> <p>Use R-Studio/Aspseq only for data exploration and visualization. Loading heavy data sets or performing memory intensive tasks like sequence alignments etc. will break the server.  All steps before this should be done using <code>bash</code>.</p> <p>test</p>"},{"location":"3.%20Resources/","title":"Resources","text":""},{"location":"3.%20Resources/#server-infrastructure","title":"Server Infrastructure","text":"<p>At UPSCb we have our own servers for both computation and storage. We also use regional and national resources.</p>"},{"location":"3.%20Resources/#local","title":"Local","text":"<p>Our on-site machines are used for both computation and storage. A few names you will come across frequently are <code>riboexplorer</code>, <code>aspseq</code> and <code>microasp</code>. All of these machines are accessed via <code>ssh</code>(more information on accessing these can be found in the Onboarding tab).</p>"},{"location":"3.%20Resources/#nationalregional","title":"National/Regional","text":"<p>High Performance Computing Center North (HPC2N) offers an Open On Demand system to request and use their resources. We will help you gain access to this resource and provide intial training to use it. There are several such computing centers in Sweden operating under the National Academic Infrastructure for Super\u00adcomputing in Sweden (NAISS) umbrella. Access to these can be discussed according to the computational needs of individual projects. </p>"},{"location":"3.%20Resources/#further-reading","title":"Further reading","text":"<p>Depending on your experience you may not be familiar with resources and terms we use frequently. Here you will find information to learn about these resources.</p> <ol> <li> <p>Git: </p> <ul> <li>In technical terms: Git is a version control system (VCS) used to track changes to your source code. You can learn more about Git here. </li> <li>Learn about Git in not-so tech terms: here</li> </ul> </li> <li> <p>Github: GitHub hosts public and private code documented using Git. </p> </li> <li> <p>R and R-studio: R (programming language) and R-Studio (an integrated development environment for R) are important tools that are used frequently in UPSCb data anlaysis pipelines. If you are not familiar with R and want to learn basic principles of R, please go through these resources: swirl, discovR</p> </li> <li> <p>SLURM: It is a queueing system meant to ensure the concurrent and fair use of a compute cluster. You can learn more about SLURM and SLURM commands like <code>sbatch</code> and <code>squeue</code> here</p> </li> <li> <p>Containers: As the name suggests, containers allow code for target tools/applications to be packaged and isolated (in other words: contained) alongwith their dependecies. In practice, it makes it easy for different users to run the tools consistently regardless of their run environment. A video explaination can be found here</p> <ul> <li>More information about the containers we use frequently and their usage can be found here</li> </ul> </li> </ol>"},{"location":"4.%20R/","title":"R-Studio","text":"<p>As mentioned in the Onboarding tab, we host our R-Studio on the server using Posit. It is hosted on <code>https://aspseq.upsc.se:8080/</code>. </p> <p>Reminder</p> <p>R-Studio should be used only for data exploration and visualization. DO NOT LOG ON TO R-Studio to</p> <ul> <li>Run data analysis pipeline</li> <li>Run or submit <code>SLURM</code> jobs</li> </ul>"},{"location":"4.%20R/#running-memory-intensive-r-scripts","title":"Running memory intensive R scripts","text":"<p>Sometimes you actually need lots of memory to successfully run an R script. No problem, just do not run it on AspSeq! </p> <p>In this case you can run the R script using <code>SLURM</code>. Here is how:</p> <ol> <li> <p>Save your R script to an R file, and make sure that it exports its results to a file.</p> </li> <li> <p>Write an <code>.sh</code> file like the following one, which contains the instructions to execute your R script e.g 'my_script.R':</p> </li> </ol> <pre><code>#!/bin/bash\n#SBATCH --account=YOUR_PROJECT_CODE\n#SBATCH --ntasks=1\n#SBATCH --time=10:00:00\n#SBATCH --mem=10G\n\nR=/mnt/picea/home/singularity/R-4.4.3.sif \nRlib=/mnt/picea/home/rstudio/Modules/apps/compilers/R/4.4.3/lib/R/library:/usr/local/lib/R/library\n\nexport R_LIBS=/mnt/picea/home/rstudio/Modules/apps/compilers/R/4.4.3/lib/R/library\n\napptainer exec -e -B /mnt:/mnt -B $Rlib $R Rscript \\\n--vanilla my_script.R\n</code></pre>"},{"location":"4.%20R/#installing-packages","title":"Installing packages","text":"<p>Most commonly used packages are already installed on the server. However, there maybe instances where you need to install your own R-Packages. In most cases this is as easy as logging on to <code>aspseq</code> and running <code>&gt;install.packages(\"package1\")</code>. </p> <p>In some cases, where you need to run the R-script through the <code>SLURM</code> queue, the process has a few more steps. When run via <code>SLURM</code> R is run thorugh a container. So it is important that the packages you install are installed in the library for the right version of R. </p>"},{"location":"4.%20R/#r-scripts","title":"R scripts","text":"<p>Several R scripts for generating a variety of plots or doing different analysis are available in the UPSCb-common repository and should be available in your home directory once you have cloned it as shown in the Onboarding tab. </p> <p>Other important scrpits are BiologicalQA.R/Rmd, and DifferentialExpression_WithGOenrichment.Rmd. These are available in the <code>Templates</code> directory of the repository and more information about them is in the Templates tab. </p>"},{"location":"4.%20R/#resolving-issues-by-yourself","title":"Resolving Issues by yourself","text":"<p>While we are always happy to help, here are some Rstudio common issues and how to try and resolve them. </p>"},{"location":"5.%20nextflow/","title":"Nextflow","text":"<p>Nextflow is a workflow manager that co-ordinates multiple steps in a pipeline. Think of it as SLURM but instead of managing multiple jobs likely submitted by multiple users, Nextflow will manage all steps in your pipeline. So instead of running FastQC and waiting for its results to feed to an aligner, you just run the whole pipeline at once.   </p> <p>nf.core is an open source database of pipelines you can use to do your analysis. We use the RNA-seq pipeline from nf.core for the analysis in the facility. </p> <p>Scripts for running the analysis using the Nextflow pipeline are also available in the <code>UPSCb-common</code> repository. </p> <p>Caution</p> <p>Be sure to modify the <code>.config</code> and <code>.json</code> files to correctly provide the source files that you want to analyse before running the pipeline.</p>"},{"location":"5.%20nextflow/#nextflow-installation","title":"Nextflow Installation","text":"<p>Brief instructions on how to install Nextflow:</p>"},{"location":"5.%20nextflow/#prerequisites","title":"Prerequisites:","text":"<ol> <li>Install java from OpenJDK. Select version 1.18.0.2 (the latest one known to work with NF - 2023-03-13), choose <code>Linux X64</code>. Right click and save the link. (Version 24GA works - 2025-06-05). As it seems to be working with more recent Java version, one can also aim for the latest GA version, 24 on 2025-06-05.</li> <li>use <code>wget</code> to download it in your home dir on the server</li> <li>decompress the archive, then delete the archive</li> <li>create a <code>~/bin</code> directory if it does not exists in your home dir</li> <li>cd into the <code>~/bin</code> directory</li> <li>create a link to all the java executables: <code>ln -s ../jdk-18.0.2/bin/* .</code></li> <li>exit your terminal and start a new one</li> </ol>"},{"location":"5.%20nextflow/#installation","title":"Installation","text":"<ol> <li>Run <code>curl -s https://get.nextflow.io | bash</code></li> <li><code>mv nextflow bin</code> to move the newly created executable to your bin dir</li> <li>give the command <code>nextflow</code> a try</li> </ol>"},{"location":"5.%20nextflow/#configuration","title":"Configuration","text":"<p>To be able to run on system running SLURM, you'll need to set up and use a profile.</p>"},{"location":"5.%20nextflow/#profiles","title":"Profiles","text":"<p>In your config file, you will need to set  profile and you will need to have that profile used by nextflow (<code>-profile</code> on the command line - see the doc)</p> <p>Here is an example profile that will work on UPPMAX, just change the account to run on the UPSC servers. (Commented out some lines to prevent auto-retries)</p> <pre><code>// Profile\nprofiles {\n\n    // Uppmax general profile\n    uppmax {\n        params{\n          account        = 'snic2022-5-342'\n            email = 'nicolas.delhomme@umu.se'\n            mailType = 'END,FAIL'\n        }\n        process {\n            executor       = 'slurm'\n            clusterOptions = \"-A '${params.account}' --mail-type '${params.mailType}' --mail-user '${params.email}'\"\n//            memory         = { 20.GB * task.attempt }\n            cpus           = { 1 * task.attempt }\n            time           = { 10.h * task.attempt }\u00df\u00df\u00df\n            scratch        = '$SNIC_TMP'\n//            errorStrategy  = 'retry'\n//            maxRetries     = 2\n        }\n    }\n}\n</code></pre>"},{"location":"5.%20nextflow/#running","title":"Running","text":"<p>Make sure to set the <code>NXF_HOME</code> to be in the project dir and not your home dir:</p> <p>As on UPPMAX:</p> <pre><code>Note that NXF_HOME is set to $HOME/.nextflow\nPlease change NXF_HOME to a place in your project directory (export NXF_HOME=yourprojectfolder)\n</code></pre> <p>Meaning, you should:</p> <p><code>export NXF_HOME=/mnt/ada/projects/pine/nstreet/pine-leaf-fungi/nextflow</code></p>"},{"location":"6.%20pipeline/","title":"Pipeline","text":"<p>While most of the standard anlaysis in the facility is now done using Nextflow pipelines, we still have our own framework of scripts that we use for some steps of a standard analysis or for some non-standard analysis. This resource hosted on Github contains scripts written (mostly) in bash that you can copy into your project and used through the SLURM queueing system. Most of these scripts rely on containers. </p>"},{"location":"7.%20templates/","title":"Templates","text":"<p>Before re-inventing the wheel, check the templates directory! A number of useful templates are available there:</p> <ol> <li> <p>This directory contains code templates for Biological quality analysis and Differetnial expression analysis in the RNA-Seq pipeline</p> <ul> <li>BiologicalQA.R: a template to perform the biological QA of RNA-Seq data quantified by salmon</li> <li>DifferentialExpression.R: a template to perform the differential expression of RNA-Seq data using DESeq2</li> </ul> <p>The templates contain <code>CHANGEME</code> tokens, where changes need to be made to adjust to your project. The <code>R</code> templates are written using the <code>#'</code> comments that allow for the knitting of <code>Rmd</code> files and <code>html</code> reports.</p> <p>Some of the <code>CHANGEME</code> tokens are within markdown code block. These are meant to be invisible when knitting (<code>eval=FALSE, echo=FALSE</code>), so you need NOT change them, just follow the instructions they contain to edit the subsequent code.</p> <p>The templates are not completely self-explanatory and as such the report generated from them will not be. Spend time to comment and interpret the results you observe using <code>#'</code> comments. These will be turned into text when knitting.</p> <p>The templates expect the following directory structure.  <pre><code>project/  \n\u251c\u2500\u2500  src/R        - where your custom R code resides\n\u251c\u2500\u2500  doc          - where the relevant sample information can be found\n\u251c\u2500\u2500  UPSCb-common - the checkout of the GitHub UPSCb/UPSCb-common repository, best as a submodule to your project\n\u251c\u2500\u2500 data         - a link to the data directory\n\u2502    \u2514\u2500\u2500 salmon - the directory containing the salmon results. One directory per sample, each containing the salmon results for that sample\n\u2514\u2500\u2500 reference a link to the reference genomic information (_e.g._ transcript to gene mapping file)\n</code></pre></p> </li> <li> <p>Helper files</p> <p>These are styling files you need for proper formatting of the reports from these scripts as well as adding some logos etc.</p> <ul> <li>bulogo2.png </li> <li>style.css: Controls the width and margins of the report</li> <li>header.html: This adds the little Github logo in the top corner</li> <li>footer.html: this adds the logo and the links at the bottom of the report. You need to edit for your name and links</li> <li>Mfuzz.R: Only for co-expression analysis</li> </ul> </li> </ol>"},{"location":"HPC2N/","title":"HPC2N","text":"<p>As mentioned in the Resources tab, you can also access HPC2N resources. Comprehensive documentation on how to use and access HPC2N is available here. Below you will find information on how to get started.</p>"},{"location":"HPC2N/#suprnaiss-account","title":"SUPR/NAISS account","text":"<p>Since HPC2N is under the SUPR/NAISS umbrella, the first step is to get a NAISS account. To do that </p> <ul> <li>Go to the account registration of NAISS: https://supr.naiss.se/person/register (skip if you already have an account)</li> <li> <p>Select \"Register with Federated Identity\"</p> </li> <li> <p>Select Ume\u00e5 University (or other if relevant)</p> </li> <li> <p>Login with your credentials. If that step does not work, please get in touch. Otherwise proceed to the next step.</p> </li> </ul>"},{"location":"HPC2N/#request-access-to-a-project","title":"Request access to a project","text":"<p>In order for you to access the services, you need to be a member of a project. In most cases, this will be something that your PI or the facility will have created for you. To request access to a project </p> <ul> <li> <p>Once logged in on SUPR/NAISS, click on the Project link in the left menu</p> </li> <li> <p>Request Membership of a relevant project. You can look for projects assigned to PIs by searching the PIs name. </p> </li> <li> <p>You will be granted access once your PI or the facility approves the request.</p> </li> <li> <p>Get in touch if anything of the above fails, otherwise proceed to the next step once you have gotten confirmation by email that you have been added to the project.</p> </li> </ul>"},{"location":"HPC2N/#hpc2n-account","title":"HPC2N account","text":"<ul> <li>Once logged in in SUPR/NAISS, click on the Accounts link in the left menu</li> <li> <p>In the section \"Account Request\" you will see your name listed next to Kebnekaise at HPC2N. Click on Request Account</p> </li> <li> <p>You will be contacted by HPC2N by email once your account is ready. They will let you know your username and password. This usually takes a few days as they make new accounts once a week. </p> </li> </ul>"},{"location":"HPC2N/#testing-your-access","title":"Testing your access","text":"<p>Almost there!</p> <ul> <li> <p>Open the HPC2N OnDemand portal: https://portal.hpc2n.umu.se/public/landing_page.html</p> </li> <li> <p>Log in with your credentials</p> </li> </ul>"}]}